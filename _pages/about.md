---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Currently, I am a second-year PhD student in Computer Science at the Computer Vision Group in the School of Electronic Engineering and Computer Science at the Queen Mary University of London, under the supervision of [Prof. Shaogang Gong](http://www.eecs.qmul.ac.uk/~sgg/).

My research aim is to answer the question: In what ways can large language models be optimally utilized to facilitate multimodal learning in fine-grained unsupervised domain adaptation and domain generalization? Consequently, I am deeply interested in generative models, multimodal, and domain generalization.


# üî• News
- *2025.03*: &nbsp;üéâüéâ Two papers were accepted to **CVPR'25**!
- *2024.10*: &nbsp;üéâüéâ One paper was accepted to **WACV'25 <span style="color:red">(Oral)</span>**!
- *2024.07*: &nbsp;üéâüéâ One paper was accepted to **ECCV'24**!

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/ASCED.png' alt="CVPR2025" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts](https://arxiv.org/pdf/2503.16218)  
**CVPR 2025**

**Yu Cao**, Zengqun Zhao, Ioannis Patras, Shaogang Gong

[**Project**](https://yucao16.github.io/ASCED/) **|** [**Code**](https://github.com/YuCao16/ASCED)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/AIM-Fair.png' alt="CVPR2025" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning Biased Models with Contextual Synthetic Data](https://arxiv.org/abs/2503.05665)  
**CVPR 2025**

Zengqun Zhao, Ziquan Liu, **Yu Cao**, Shaogang Gong, Ioannis Patras

[**Project**](https://zengqunzhao.github.io/AIMFair) **|** [**Code**](https://github.com/zengqunzhao/AIM-Fair)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">WACV 2025</div><img src='images/Exp-CLIP.png' alt="WACV2025" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge Transfer](https://arxiv.org/abs/2405.19100)  
**WACV 2025 <span style="color:red">(Oral)</span>**

Zengqun Zhao, **Yu Cao**, Shaogang Gong, Ioannis Patras

[**Code**](https://github.com/zengqunzhao/Exp-CLIP)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/CRDI.png' alt="ECCV2024" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Few-Shot Image Generation by Conditional Relaxing Diffusion Inversion](https://arxiv.org/abs/2407.07249)  
**ECCV 2024 (Poster)**

**Yu Cao**, Shaogang Gong

[**Project**](https://yucao16.github.io/CRDI/) **|** [**Code**](https://github.com/YuCao16/CRDI)
</div>
</div>

# üéñ Honors and Awards
- *2021.12* Computer Science **Dean's list**, University College London, UK.

# üìñ Educations
- *2023.09 - Now, PhD, Queen Mary University of London (QMUL), London, UK.
- *2020.09 - 2021.09*, Master (Distinct GPA 4.0), University College London (UCL), London, UK.
- *2016.09 - 2020.09*, Bachelor (First-Class Honours, GPA 4.0), University of Liverpool, Liverpool, UK.

# üíª Internships
- *2024.06 - Now*, Research Assistant, Digital Environment Research Institute (QMUL), UK.
- *2023.12 - 2024.05*, Research Asistant, Scalpel Limited, UK.
